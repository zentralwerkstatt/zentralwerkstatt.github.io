| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  |
| :---- | :---- |
<p class="large">Vector Media<p>

**Johanna Drucker (foreword), Leonardo Impett & Fabian Offert (joint authors)**  
***In Search of Media*** **series, Meson Press & University of Minnesota Press, 2025**

Bias in large visual models is not just a question of what is represented but of the logic of representation itself. ImageNet – one of the most popular previous-generation datasets – thus  sees the world as a collection of singular, industrially manufactured consumer goods. But the mapping from training data to trained model is always messy and indirect. If we thus want to better understand the place of large visual models within our contemporary visual culture, we will have to ask more difficult questions about the ideologies (and, it turns out, epistemologies) of the “black boxes” themselves.  

Following Phil Agre’s claim that artificial intelligence is “philosophy underneath”, we show how the “philosophy” of contemporary artificial intelligence is not to be found anymore in the famous thought experiments of Turing and Searle, but, surprisingly, in a long chain of historical attempts to compress (visual) knowledge that reaches from the first formalization of vector mathematics and dependent probabilities in the 19th century, through 1980s computational biology research, all the way to the multimodal models of the 2020s.  

What we uncover in doing so is a significant and previously little understood technical paradigm shift in artificial intelligence research that continues to shape the ideological function of these models. Their capabilities, we argue, are closely tied to the rise of a specific machine learning technique called “embedding”, a technique that has not been studied from the perspective of critical artificial intelligence studies so far. Embeddings, starting in the 1990s, are thought of, and implemented as an abstract geometry for not only *representing*, but *producing* knowledge – a development that, surprisingly, is described by the computer scientists themselves as a post-structuralist turn. Vector mathematics – of the kind employed in the famous analogy query of natural language processing, “men \+ king \= woman \+ ?” – is imagined as a mathematical tool to transcend the training data and reintroduce meaning into the embedding space. While, on the surface, it seems like technocratic notions of *human* intelligence determine the claim to power of *artificial* intelligence, it is in fact this epistemic shift that historically structures it. It is thus the epistemology of embedding that ends up shaping, even determining, the epistemology of artificial intelligence in general.  

We show how this technical-ideological turn in machine learning eventually leads to the multimodal models of today, models that seem to transcend the media boundaries of the objects they ingest. Text, image, and audio can all be represented by the same model, as just another embedding. We theorize this tendency towards *media collapse* – a centrifugal pull of commensurability that dissolves media-specific cultural objects into embeddings – as the rise of *neural exchange value*: value that specific cultural objects obtain once they become part of a multimodal embedding space.

The book unfolds through four thematic sections. The first, **Machine Visual Culture**, reframes AI art and other generative media not as cultural artifacts per se but as by-products, epiphenomenal evidence, of the computational models we are seeking to historicise and critique. The second, **Whose Vision?**, revisits philosophical debates on visual perception—from Berkeley’s theories of sight to modern theories of embodied AI—showing how neural networks embed historically contingent perceptual models and theories of the image. The principal technical and theoretical cleavage of computer vision, between James Gibson and David Marr, is in fact a continuation of Enlightenment debates about visuality, embedded into models such as the Neocognitron. The third section, **Vector Media**, explores the relationship between vision, compression, and embedding: a conceptual amalgamation with its origins in Horace Barlow’s studies of the optic nerve. Contemporary embedding techniques redefine compression as a form of epistemic reduction, turning sensory data into abstracted forms of meaning: images into codes. It traces the development of embeddings, from linear perspective and document-search models to today’s multimodal architectures. The final section, **Neural Exchange Value**, draws parallels with Marx’s theory of commodity exchange: arguing that the defining characteristic of contemporary neural networks is precisely in their promise to extract computational value by rendering all previous media-forms exchangeable, through abstraction into embeddings. This transformation attempts to force media objects into operational commensurability, enabling their circulation, translation and manipulation within neural infrastructures.   

Most technologies produce media; neural networks, on the other hand, attempt to model media. Neural networks are thus models of models; depictions of depictions. Ultimately, *Vector Media* reveals how these internal mechanisms of artificial intelligence inscribe and enact radically new epistemologies of media. 